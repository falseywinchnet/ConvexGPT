{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPiuCZ+9RTjXrcGJniNNNy/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMyAv_7rxOyW",
        "outputId": "4321393c-40b6-4ecb-b936-a92f58e64823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n",
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n",
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Prepare the Shakespeare dataset for character-level language modeling.\n",
        "So instead of encoding with GPT-2 BPE tokens, we just map characters to ints.\n",
        "Will save train.bin, val.bin containing the ids, and meta.pkl containing the\n",
        "encoder and decoder and some other related info.\n",
        "\"\"\"\n",
        "import os\n",
        "import pickle\n",
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    base_dir = Path(__file__).parent\n",
        "except NameError:\n",
        "    base_dir = Path(os.getcwd())  # fallback if __file__ is not defined (e.g. in REPL)\n",
        "# download the tiny shakespeare dataset\n",
        "input_file_path = os.path.join(os.path.dirname(base_dir), 'input.txt')\n",
        "if not os.path.exists(input_file_path):\n",
        "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "    with open(input_file_path, 'w') as f:\n",
        "        f.write(requests.get(data_url).text)\n",
        "\n",
        "with open(input_file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(f\"length of dataset in characters: {len(data):,}\")\n",
        "\n",
        "# get all the unique characters that occur in this text\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "print(\"all the unique characters:\", ''.join(chars))\n",
        "print(f\"vocab size: {vocab_size:,}\")\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# create the train and test splits\n",
        "n = len(data)\n",
        "train_data = data[:int(n*0.9)]\n",
        "val_data = data[int(n*0.9):]\n",
        "\n",
        "# encode both to integers\n",
        "train_ids = encode(train_data)\n",
        "val_ids = encode(val_data)\n",
        "print(f\"train has {len(train_ids):,} tokens\")\n",
        "print(f\"val has {len(val_ids):,} tokens\")\n",
        "\n",
        "# export to bin files\n",
        "train_ids = np.array(train_ids, dtype=np.uint16)\n",
        "val_ids = np.array(val_ids, dtype=np.uint16)\n",
        "train_ids.tofile(os.path.join(os.path.dirname(base_dir), 'train.bin'))\n",
        "val_ids.tofile(os.path.join(os.path.dirname(base_dir), 'val.bin'))\n",
        "\n",
        "# save the meta information as well, to help us encode/decode later\n",
        "meta = {\n",
        "    'vocab_size': vocab_size,\n",
        "    'itos': itos,\n",
        "    'stoi': stoi,\n",
        "}\n",
        "with open(os.path.join(os.path.dirname(base_dir), 'meta.pkl'), 'wb') as f:\n",
        "    pickle.dump(meta, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "copyright joshuah.rainstar@gmail.com 2025\n",
        "this code may not be used without agreement to convexgpt license\n",
        "if you do not agree close this file and remove it"
      ],
      "metadata": {
        "id": "q47er8Ni84xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from pathlib import Path\n",
        "from typing import List,Literal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class S4DFFT(nn.Module):\n",
        "    \"\"\"\n",
        "    Diagonal State‑Space (S4D) layer with length‑agnostic FFT or recurrent scan.\n",
        "\n",
        "      x : (B,T,D)  ➜  y : (B,T,D)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model: int,\n",
        "        N: int          = 64,          # # diagonal modes\n",
        "        init: str       = \"hippoD\",    # 'hippoD' | 'inverse' | 'linear'\n",
        "        short_thresh: int = 512,       # switch to recurrent if T ≤ this\n",
        "        tau_min: float  = 1e-4,        # clamp on exp(log_tau)\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert N % 2 == 0, \"N must be even (conjugate pairs).\"\n",
        "\n",
        "        self.d_model, self.N = d_model, N\n",
        "        self.tau_min = tau_min\n",
        "\n",
        "        # unconstrained parameters for N/2 distinct modes\n",
        "        self.log_tau = nn.Parameter(torch.randn(N // 2))\n",
        "        self.freq    = nn.Parameter(torch.randn(N // 2))\n",
        "        self.B       = nn.Parameter(torch.randn(N // 2))\n",
        "        self.C       = nn.Parameter(torch.randn(N // 2))\n",
        "\n",
        "        # input/output projections\n",
        "        self.in_proj  = nn.Linear(d_model, N // 2, bias=False)\n",
        "        self.out_proj = nn.Linear(N // 2, d_model, bias=False)\n",
        "\n",
        "        # learnable global time‑scale Δt  (log‑domain)\n",
        "        self.log_dt = nn.Parameter(torch.zeros(()))\n",
        "\n",
        "        self._init_modes(init)\n",
        "\n",
        "    # ----- initialisers --------------------------------------------------\n",
        "    def _init_modes(self, kind: Literal[\"hippoD\", \"inverse\", \"linear\"]):\n",
        "        n = torch.arange(self.N // 2)\n",
        "        with torch.no_grad():\n",
        "            self.log_tau.fill_(math.log(0.5))\n",
        "            if kind == \"hippoD\":\n",
        "                self.freq.copy_(math.pi * (2*n + 1) / 2)\n",
        "            elif kind == \"inverse\":\n",
        "                self.freq.copy_((self.N / math.pi) / (2*n + 1))\n",
        "            elif kind == \"linear\":\n",
        "                self.freq.copy_(math.pi * n)\n",
        "            else:\n",
        "                raise ValueError(kind)\n",
        "            nn.init.normal_(self.B,  mean=1.0, std=0.2)\n",
        "            nn.init.normal_(self.C,  std=1.0 / math.sqrt(self.N/2))\n",
        "\n",
        "    # ---------------------------------------------------------------------------\n",
        "    # Real‑only kernel builder\n",
        "    # ---------------------------------------------------------------------------\n",
        "    def _kernel_fft(self, T: int):\n",
        "        \"\"\"\n",
        "        Return RFFT(K) where K is the real convolution kernel of length T.\n",
        "          output: (N, L/2+1) complex\n",
        "        Everything up to the final rfft is real‑typed.\n",
        "        \"\"\"\n",
        "        L   = self._next_pow_two(2 * T)\n",
        "\n",
        "        dt   = torch.exp(self.log_dt)                      # scalar\n",
        "        tau  = torch.exp(self.log_tau).clamp(min=self.tau_min)   # (N/2,)\n",
        "        angle = self.freq * dt                                   # (N/2,)\n",
        "\n",
        "        # |lam|  = exp(-tau*dt)            (real)\n",
        "        # arg(lam)= angle                  (real)\n",
        "        lam_mag = torch.exp(-tau * dt)                         # (N/2,)\n",
        "        log_gain = (self.B.abs() + 1e-9).log() + \\\n",
        "                  (self.C.abs() + 1e-9).log()                 # (N/2,)\n",
        "\n",
        "        i = torch.arange(T, device=tau.device)                 # (T,)\n",
        "\n",
        "        # amplitude term  (N/2,T)   — still real\n",
        "        log_lam_mag = lam_mag.log()\n",
        "        scaled_i = i[None] * log_lam_mag[:, None]\n",
        "        amp = torch.exp(log_gain[:, None] + scaled_i)\n",
        "\n",
        "        # phase term\n",
        "        phase = i[None] * angle[:, None]                       # (N/2,T)\n",
        "\n",
        "        K_half = amp * torch.cos(phase)                        # (N/2,T) real\n",
        "\n",
        "        # build full length‑N kernel (conjugate pair ⇒ symmetry in mode index)\n",
        "        K_full = torch.cat([K_half, K_half.flip(0)], dim=0)     # (N,T) real\n",
        "\n",
        "        return torch.fft.rfft(K_full, n=L, dim=-1)             # (N,L/2+1) complex\n",
        "\n",
        "    @staticmethod\n",
        "    def _next_pow_two(n: int) -> int:\n",
        "        # smallest power of two ≥ n, in O(1) bit ops\n",
        "        # (from Hacker’s Delight)\n",
        "        n = n - 1\n",
        "        n = n | (n >> 1)\n",
        "        n = n | (n >> 2)\n",
        "        n = n | (n >> 4)\n",
        "        n = n | (n >> 8)\n",
        "        n = n | (n >> 16)\n",
        "        n = n | (n >> 16)\n",
        "\n",
        "        # if you worry about >32‐bit dims, add: n |= (n >> 32)\n",
        "        return n + 1\n",
        "\n",
        "    # ----- forward (FFT or scan) ----------------------------------------\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        B, T, _ = x.shape\n",
        "        x_proj  = self.in_proj(x)                               # (B,T,N/2)\n",
        "        x_modes = torch.cat([x_proj, x_proj.flip(-1)], dim=-1)  # (B,T,N)  real\n",
        "\n",
        "        L  = self._next_pow_two(2 * T)\n",
        "        Uf = torch.fft.rfft(x_modes, n=L, dim=1).transpose(1, 2)   # (B,N,L/2+1)\n",
        "\n",
        "        Kf = self._kernel_fft(T)                                   # (N,L/2+1)\n",
        "        Yf = Uf * Kf[None]                                         # broadcast\n",
        "\n",
        "        y_modes = torch.fft.irfft(Yf, n=L, dim=2)[..., :T]          # (B,N,T)\n",
        "        y_modes = y_modes.transpose(1, 2)                          # (B,T,N)\n",
        "        y       = y_modes[..., : self.N // 2]                       # (B,T,N/2)\n",
        "        return self.out_proj(y)\n",
        "\n",
        "class S4PreMix(nn.Module):\n",
        "    def __init__(self, embed_dim: int, heads: int):\n",
        "        super().__init__()\n",
        "        # compute per-head and inner dimensions\n",
        "        assert embed_dim % heads == 0, \"embed_dim must be divisible by heads\"\n",
        "        self.heads = heads\n",
        "        self.d_k = embed_dim // heads\n",
        "        assert self.d_k % 2 == 0 , \"self.d_dk must be divisible by 2\"\n",
        "\n",
        "        # choose number of modes = d_k\n",
        "        self.N_modes = self.d_k//2 #cannot meaningfully use more than self.dk, optimizing for half- a low pass.\n",
        "        # S4D preprocessing\n",
        "        self.s4d = S4DFFT(d_model=self.d_k, N=self.N_modes)\n",
        "        # QKV projection at inner_dim = embed_dim\n",
        "        self.qkv = nn.Linear(embed_dim, 3 * embed_dim, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        # x: (B, S, embed_dim)\n",
        "        B, S, E = x.shape\n",
        "        # apply per-head S4 after projecting to embed_dim\n",
        "        x = x.view(B * self.heads, S, self.d_k)\n",
        "        x = self.s4d(x)\n",
        "        x = x.view(B, S, E)\n",
        "        # compute QKV\n",
        "        q, k, v = self.qkv(x).chunk(3, dim=-1)\n",
        "        # reshape to heads\n",
        "        q = q.view(B, S, self.heads, self.d_k).transpose(1,2)\n",
        "        k = k.view(B, S, self.heads, self.d_k).transpose(1,2)\n",
        "        v = v.view(B, S, self.heads, self.d_k).transpose(1,2)\n",
        "        return q, k, v\n",
        "\n",
        "class LinearPreMix(nn.Module):\n",
        "    def __init__(self, embed_dim: int, heads: int):\n",
        "        super().__init__()\n",
        "        assert embed_dim % heads == 0, \"embed_dim must be divisible by heads\"\n",
        "        self.heads = heads\n",
        "        self.d_k = embed_dim // heads\n",
        "        # direct QKV projection\n",
        "        self.qkv = nn.Linear(embed_dim, 3 * embed_dim, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        # x: (B, S, embed_dim)\n",
        "        B, S, E = x.shape\n",
        "        q, k, v = self.qkv(x).chunk(3, dim=-1)\n",
        "        q = q.view(B, S, self.heads, self.d_k).transpose(1,2)\n",
        "        k = k.view(B, S, self.heads, self.d_k).transpose(1,2)\n",
        "        v = v.view(B, S, self.heads, self.d_k).transpose(1,2)\n",
        "        return q, k, v\n",
        "\n",
        "\n",
        "class BatchedICNN(nn.Module):\n",
        "    def __init__(self, in_dim: int, petals: int):\n",
        "        super().__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.P = petals\n",
        "        D = in_dim\n",
        "        # layer dims: D → 2D → D\n",
        "        self.d1, self.d2 = 2 * D, D\n",
        "\n",
        "        # first-layer weights: (P, d1, D)\n",
        "        self.weight_raw_0 = nn.Parameter(self._init_weight(petals, self.d1, D))\n",
        "        self.bias_0       = nn.Parameter(torch.zeros(petals, self.d1))\n",
        "\n",
        "        # second-layer weights: (P, d2, d1)\n",
        "        self.weight_raw_1 = nn.Parameter(self._init_weight(petals, self.d2, self.d1))\n",
        "        self.bias_1       = nn.Parameter(torch.zeros(petals, self.d2))\n",
        "\n",
        "        # per-petal residual projection weight: maps 2D → D: shape (P, d1, d2)\n",
        "        self.z_weight = nn.Parameter(torch.empty(petals, self.d1, self.d2))\n",
        "        nn.init.kaiming_uniform_(self.z_weight, a=math.sqrt(5))\n",
        "\n",
        "        # gating scalars\n",
        "        self.gate_raw_0 = nn.Parameter(torch.full((petals,), -3.0))\n",
        "        self.gate_raw_1 = nn.Parameter(torch.full((petals,), -3.0))\n",
        "\n",
        "        self.output_bias = nn.Parameter(torch.zeros(petals, D))\n",
        "        self.act = nn.Softplus()\n",
        "\n",
        "    def _init_weight(self, petals: int, d_out: int, d_in: int) -> torch.Tensor:\n",
        "        w = torch.empty(petals, d_out, d_in)\n",
        "        with torch.no_grad():\n",
        "            mean = math.log(math.sqrt(2.0 / d_in))\n",
        "            nn.init.normal_(w, mean=mean, std=0.2)\n",
        "        return w\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (..., D)\n",
        "        orig = x.shape\n",
        "        x_flat = x.reshape(-1, self.in_dim)          # (N, D)\n",
        "        N = x_flat.size(0)\n",
        "\n",
        "        # prepare weights & gates\n",
        "        w0 = F.softplus(self.weight_raw_0).pow(2)    # (P, 2D, D)\n",
        "        w1 = F.softplus(self.weight_raw_1).pow(2)    # (P, D, 2D)\n",
        "        g0 = torch.sigmoid(self.gate_raw_0).view(self.P, 1, 1)  # (P,1,1)\n",
        "        g1 = torch.sigmoid(self.gate_raw_1).view(self.P, 1, 1)\n",
        "\n",
        "        # ----- first layer across petals -----\n",
        "        x_in = x_flat.unsqueeze(0).expand(self.P, N, self.in_dim)       # (P, N, D)\n",
        "        x_w0 = torch.bmm(x_in, w0.transpose(1,2))                       # (P, N, 2D)\n",
        "        x_w0 = x_w0 + self.bias_0.unsqueeze(1)                          # (P, N, 2D)\n",
        "        z0   = self.act(x_w0 * g0)                                      # (P, N, 2D)\n",
        "\n",
        "        # ----- second layer -----\n",
        "        x_w1 = torch.bmm(z0, w1.transpose(1,2))                         # (P, N, D)\n",
        "        x_w1 = x_w1 + self.bias_1.unsqueeze(1)                          # (P, N, D)\n",
        "\n",
        "        # ----- residual path via bmm -----\n",
        "        # z_weight: (P, 2D, D), z0: (P, N, 2D) → z_mapped: (P, N, D)\n",
        "        z_mapped = torch.bmm(z0, self.z_weight)                         # (P, N, D)\n",
        "\n",
        "        # combine, activate, add final bias\n",
        "        z1 = self.act(x_w1 * g1 + z_mapped)                             # (P, N, D)\n",
        "        out = z1 + self.output_bias.unsqueeze(1)                        # (P, N, D)\n",
        "\n",
        "        # reshape back to original leading dims + (P, D)\n",
        "        out = out.permute(1, 0, 2)  # (N, P, D)\n",
        "        lead_dims = list(orig[:-1])                 # e.g. [B, H, T]\n",
        "        new_shape = lead_dims + [self.P, self.in_dim]  # [B, H, T, P, D]\n",
        "        return out.reshape(new_shape)\n",
        "\n",
        "\n",
        "class ConvexGate(nn.Module):\n",
        "    \"\"\"\n",
        "    Convex & bounded gate: g(x) = 1 - exp(-softplus(Wx + b)) ∈ (0,1)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim: int):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(in_dim, 1, bias=True)\n",
        "        self.softplus = nn.Softplus()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        u = self.softplus(self.lin(x))      # convex, ≥ 0\n",
        "        return 1.0 - torch.exp(-u)       # convex, ∈ (0,1)\n",
        "\n",
        "class _FusedLogSumExp(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, dim):\n",
        "        m, _ = x.max(dim=dim, keepdim=True)\n",
        "        y = x - m\n",
        "        ex = y.exp()\n",
        "        s = ex.sum(dim=dim, keepdim=True)\n",
        "        lse = m + s.log()\n",
        "        ctx.save_for_backward(ex, s)\n",
        "        ctx.dim = dim\n",
        "        return lse\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        ex, s = ctx.saved_tensors\n",
        "        dim = ctx.dim\n",
        "        grad_x = grad_output * (ex / s)\n",
        "        return grad_x, None\n",
        "\n",
        "# TorchScript-compatible wrapper\n",
        "class FusedLogSumExp(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    @torch.jit.ignore\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return _FusedLogSumExp.apply(x, self.dim)\n",
        "\n",
        "\n",
        "\n",
        "class ScalarHull(nn.Module):\n",
        "    def __init__(self, in_dim: int, petals: int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('nu',  torch.log(torch.tensor(2.71828)))\n",
        "        self.register_buffer('noise_scale', torch.tensor(1e-5))\n",
        "        self.petals = BatchedICNN(in_dim, petals)\n",
        "        self.gate   = ConvexGate(in_dim)\n",
        "        self.register_buffer(\"creative\", torch.tensor(True))\n",
        "        self.register_buffer('eps', torch.tensor(1e-6))\n",
        "        self.fused_lse_hulls = FusedLogSumExp(dim=-1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (..., D)\n",
        "        g   = self.gate(x)                                   # (..., 1)\n",
        "\n",
        "        #creativity toggle here\n",
        "\n",
        "        if self.creative:\n",
        "            xg   = (x + torch.randn_like(x) * self.noise_scale) * g # (..., D)\n",
        "        else:\n",
        "            xg   = x  * g # (..., D)\n",
        "\n",
        "        # compute τ\n",
        "        r   = torch.sqrt(xg.pow(2).mean(dim=-1, keepdim=True) + self.eps)  # (..., 1)\n",
        "        tau = torch.sqrt(r.pow(2) + self.nu)                               # (..., 1)\n",
        "\n",
        "        # get each petal’s vector output, then reduce to scalar per petal\n",
        "        out_all = self.petals(xg)                  # (..., P, D)\n",
        "        scores  = out_all.mean(dim=-1)             # (..., P)\n",
        "\n",
        "        # tempered LSE over petals\n",
        "        # scaled: (..., P) = scores * τ\n",
        "        scaled = scores * tau                     # broadcasts τ→[...,1]→[...,P]\n",
        "\n",
        "        lse    = self.fused_lse_hulls(scaled)  # (..., 1)\n",
        "\n",
        "        # divide by τ and squeeze\n",
        "        return (lse / tau).squeeze(-1)             # (...,)\n",
        "\n",
        "class VectorHull(nn.Module):\n",
        "    def __init__(self, dim: int, petals: int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('nu',  torch.log(torch.tensor(2.71828)))\n",
        "        self.register_buffer('noise_scale', torch.tensor(1e-5))\n",
        "        self.petals = BatchedICNN(dim, petals)\n",
        "        self.gate   = ConvexGate(dim)\n",
        "        self.register_buffer(\"creative\", torch.tensor(True))\n",
        "        self.register_buffer('eps', torch.tensor(1e-6))\n",
        "        self.fused_lse_hulls = FusedLogSumExp(dim=-1)    # <— same as in ScalarHull\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (..., D)\n",
        "        g    = self.gate(x)                             # (..., 1)\n",
        "\n",
        "        #creativity toggle here\n",
        "        if self.creative:\n",
        "            xg   = (x + torch.randn_like(x) * self.noise_scale) * g # (..., D)\n",
        "        else:\n",
        "            xg   = x  * g # (..., D)\n",
        "\n",
        "        # compute τ\n",
        "        r    = torch.sqrt(xg.pow(2).mean(dim=-1, keepdim=True) + self.eps)  # (..., 1)\n",
        "        tau  = torch.sqrt(r.pow(2) + self.nu)                              # (..., 1)\n",
        "\n",
        "        # batched petals → one vector per petal\n",
        "        out_all = self.petals(xg)                # (..., P, D)\n",
        "\n",
        "        # tempered LSE per feature: multiply each petal-vector by τ\n",
        "        # tau.unsqueeze(-1): (..., 1, 1) → broadcasts to (..., P, D)\n",
        "        # currently: scaled shape = (..., P, D)\n",
        "        scaled = out_all * tau.unsqueeze(-1)\n",
        "\n",
        "        # 1) move petal axis to the end\n",
        "        scaled = scaled.transpose(-2, -1)       # now shape (..., D, P)\n",
        "\n",
        "        # 2) fused‐LSE over −1\n",
        "        lse = self.fused_lse_hulls(scaled)          # shape (..., D, 1)\n",
        "\n",
        "        # 3) remove the singleton\n",
        "        lse = lse.squeeze(-1)                  # shape (..., D)\n",
        "\n",
        "        # 4) divide by τ\n",
        "        return lse / tau                    # (..., D)\n",
        "\n",
        "class ConvexPositionalBias(nn.Module):\n",
        "    \"\"\"\n",
        "    Bias(i,j) = - w * |i-j|    with   w ≥ 0  (learned per head)\n",
        "    Convex in positional indices; monotone non‑increasing with distance.\n",
        "    \"\"\"\n",
        "    def __init__(self, heads):\n",
        "        super().__init__()\n",
        "        self.w_raw = nn.Parameter(torch.zeros(heads))   # raw parameter\n",
        "        self.softplus = nn.Softplus()\n",
        "\n",
        "    def forward(self, S: int):\n",
        "        device = self.w_raw.device\n",
        "        w = self.softplus(self.w_raw)                      # (H,)\n",
        "        pos  = torch.arange(S, device=device, dtype=torch.float32)\n",
        "        dist = (pos.unsqueeze(0) - pos.unsqueeze(1)).abs()  # (S,S)\n",
        "        bias = - w[:, None, None] * dist                # (H,S,S)\n",
        "        return bias\n",
        "\n",
        "\n",
        "class ConvexMixer(nn.Module):\n",
        "    def __init__(self, d_k: int, petals: int, r: int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('nu',    torch.tensor(2.71828))\n",
        "        self.register_buffer('eps',   torch.tensor(1e-6))\n",
        "        self.register_buffer('noise_scale', torch.tensor(1e-5))\n",
        "\n",
        "        self.score_q = ScalarHull(d_k, petals)\n",
        "        self.score_k = ScalarHull(d_k, petals)\n",
        "        self.gate    = nn.Softplus()\n",
        "        self.lin_h_q = nn.Linear(d_k, r, bias=False)\n",
        "        self.lin_h_k = nn.Linear(d_k, r, bias=False)\n",
        "        self.register_buffer(\"creative\", torch.tensor(True))\n",
        "        # remove fused_lse_mixer entirely\n",
        "\n",
        "    def forward(self,\n",
        "                q: torch.Tensor,           # (B,H,S,d_k)\n",
        "                k: torch.Tensor,           # (B,H,S,d_k)\n",
        "                v: torch.Tensor,           # (B,H,S,d_k)\n",
        "                extra_score: torch.Tensor, # (B,H,S,S)\n",
        "                mask: torch.Tensor         # (B,H,S,S)\n",
        "               ) -> torch.Tensor:          # returns (B,H,S,d_k)\n",
        "\n",
        "        B, H, S, D = q.shape\n",
        "\n",
        "        # ——— 1) tau ———\n",
        "        gate_q = self.gate(q)                          # (B,H,S,d_k)\n",
        "        q_pert = q * gate_q\n",
        "        rms    = torch.sqrt(q_pert.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "        tau    = torch.sqrt(rms.pow(2) + self.nu)      # (B,H,S,1)\n",
        "\n",
        "        # ——— 2) scalar hull scores ———\n",
        "        fq = self.score_q(q)  # (B,H,S)\n",
        "        gk = self.score_k(k)  # (B,H,S)\n",
        "        if self.creative:\n",
        "            qn = (torch.rand_like(q) - 0.5) * self.noise_scale\n",
        "            kn = (torch.rand_like(k) - 0.5) * self.noise_scale\n",
        "            fq_ = self.score_q(q + qn)\n",
        "            gk_ = self.score_k(k + kn)\n",
        "            delta_fq = (fq_ - fq).detach()\n",
        "            delta_gk = (gk_ - gk).detach()\n",
        "            fq = fq - 0.1 * delta_fq\n",
        "            gk = gk - 0.1 * delta_gk\n",
        "\n",
        "        # ——— 3) random-feature kernel ———\n",
        "        phi_q = self.gate(self.lin_h_q(q).clamp(max=20.0))\n",
        "        phi_k = self.gate(self.lin_h_k(k).clamp(max=20.0))\n",
        "        kernel = phi_q.matmul(phi_k.transpose(-1,-2)) + self.eps  # (B,H,S,S)\n",
        "        logK   = kernel.log()\n",
        "\n",
        "        # ——— 4) build & mask scores ———\n",
        "        scores = fq.unsqueeze(-1) + gk.unsqueeze(-2) + logK + extra_score  # (B,H,S,S)\n",
        "        if mask.dtype == torch.bool:\n",
        "            valid = mask\n",
        "        else:\n",
        "            valid = torch.isfinite(mask)\n",
        "        scores = scores.masked_fill(~valid, -1e9)\n",
        "\n",
        "        # ——— 5) 4-D tempered LSE hull ———\n",
        "        tau4 = tau.squeeze(-1)                # (B,H,S)\n",
        "        scaled = scores * tau4.unsqueeze(-1)  # (B,H,S,S)\n",
        "\n",
        "        m, _      = scaled.max(dim=-1, keepdim=True)                     # (B,H,S,1)\n",
        "        exp_s     = torch.exp(scaled - m)                                 # (B,H,S,S)\n",
        "        exp_s     = exp_s.masked_fill(~valid, 0.0)                        # zero out masked\n",
        "        denom     = exp_s.sum(dim=-1, keepdim=True).clamp(min=self.eps)   # (B,H,S,1)\n",
        "        weights   = exp_s / denom                                          # (B,H,S,S)\n",
        "\n",
        "        # ——— 6) single batched bmm for output ———\n",
        "        w_mat = weights.reshape(B * H, S, S)  # (B*H, S, S)\n",
        "        v_mat = v.reshape(B * H, S, D)        # (B*H, S, D)\n",
        "        out   = w_mat.bmm(v_mat)              # (B*H, S, D)\n",
        "        return out.reshape(B, H, S, D)\n",
        "\n",
        "class InterleavedPhaseChannelizer(nn.Module):\n",
        "    \"\"\"\n",
        "    Embedding shape: (B, T, 2*M) == [c0, ϕ0, c1, ϕ1, ..., c_{M-1}, ϕ_{M-1}].\n",
        "    This module:\n",
        "      1. Extracts content channels ci at even indices.\n",
        "      2. Builds a deterministic distance kernel W[i,j] = 1/(1 + |i-j|), applies the causal mask.\n",
        "      3. Computes φ for each content channel: φ[b,i,m] = sum_j W[i,j] * x[b,j,2*m].\n",
        "      4. Gates each φ-channel via a softplus-activated learnable scalar.\n",
        "      5. Writes gated φ into the corresponding odd slots ϕm.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim: int, init_gate_bias: float = -3.0):\n",
        "        super().__init__()\n",
        "        assert embed_dim % 2 == 0, \"embed_dim must be even\"\n",
        "        self.embed_dim = embed_dim\n",
        "        self.M = embed_dim // 2\n",
        "        # one raw gate per channel\n",
        "        self.gate_raw = nn.Parameter(torch.full((self.M,), init_gate_bias))\n",
        "        self.softplus = nn.Softplus()\n",
        "\n",
        "    def forward(self,\n",
        "                x: torch.Tensor,   # (B, T, 2*M)\n",
        "                mask: torch.Tensor # (1, 1, T, T) boolean causal+padding mask\n",
        "    ) -> None: #return nothing\n",
        "        B, T, D2 = x.shape #1128\n",
        "        M = self.M\n",
        "        assert D2 == 2 * M\n",
        "\n",
        "        device = x.device\n",
        "        dtype = x.dtype\n",
        "\n",
        "        # 1) extract content slots ci\n",
        "        x_c = x[..., 0::2]                  # (B, T, M)\n",
        "\n",
        "        # 2) build deterministic distance kernel W[i,j] = 1 / (1 + |i-j|)\n",
        "        with torch.no_grad():\n",
        "            pos = torch.arange(T, device=device, dtype=dtype)\n",
        "            dist = (pos.unsqueeze(0) - pos.unsqueeze(1)).abs()\n",
        "            W = 1.0 / (dist + 1.0)\n",
        "            if mask is not None:\n",
        "                W = W * mask.view(T, T).to(dtype)\n",
        "            W = W / W.sum(-1, keepdim=True).clamp(min=1e-6)\n",
        "\n",
        "        # 3) apply the causal+padding mask\n",
        "        causal2d = mask.view(T, T)                          # (T, T)\n",
        "        W = W * causal2d.to(dtype)\n",
        "\n",
        "        # 4) normalize each row\n",
        "        row_sum = W.sum(-1, keepdim=True).clamp(min=1e-6)    # (T, 1)\n",
        "        W = W / row_sum                                     # (T, T)\n",
        "\n",
        "        # 5) accumulate φ[b,i,m] = sum_j W[i,j] * x_c[b,j,m]\n",
        "        #    use einsum: 'ij,bjm->bim'\n",
        "        phi = torch.einsum('ij,bjm->bim', W, x_c)           # (B, T, M)\n",
        "\n",
        "        # 6) gate each channel\n",
        "        gate = self.softplus(self.gate_raw).view(1, 1, M)   # (1, 1, M)\n",
        "        gated_phi = gate * phi                              # (B, T, M)\n",
        "\n",
        "        # 7) write into odd slots ϕm. gated_phi is computed from content-only paths. therefore: this is safe.\n",
        "        x = x.clone()\n",
        "        x[..., 1::2] = gated_phi\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "#   Pairwise Hull Attention (mask‑aware)\n",
        "# ----------------------------------------------------------------------\n",
        "class PairwiseHullAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, heads,moe_petals, use):\n",
        "        super().__init__()\n",
        "        assert embed_dim % heads == 0, \"embed_dim must be divisible by heads\"\n",
        "        self.embed_dim = embed_dim\n",
        "        self.heads = heads\n",
        "        self.d_k = embed_dim // heads\n",
        "        if use==0:\n",
        "            self.pre = S4PreMix(embed_dim, heads)\n",
        "        else:\n",
        "            self.pre = LinearPreMix(embed_dim, heads)\n",
        "        self.mixer = ConvexMixer(self.d_k, moe_petals, self.d_k*2)#dont need many for scoring\n",
        "        self.pos = ConvexPositionalBias(heads)\n",
        "        self.W_O = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "        self.phase = InterleavedPhaseChannelizer(embed_dim)\n",
        "        self.register_buffer('noise_scale', torch.tensor(1e-5))\n",
        "        self.register_buffer(\"creative\", torch.tensor(True))\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        self.phase(x,mask) #apply in-place positional phasing\n",
        "        B, S, E = x.shape\n",
        "        Q, K, V= self.pre(x)\n",
        "        mean = 0.5 * (Q.mean() + K.mean())\n",
        "        std  = 0.5 * (Q.std()  + K.std())\n",
        "        Q = (Q - mean) / std\n",
        "        K = (K - mean) / std\n",
        "\n",
        "        bias = self.pos(S).unsqueeze(0)\n",
        "        if mask is not None:\n",
        "            bias = bias.masked_fill(~mask, float('-inf'))\n",
        "        # pass bias as extra_score keyword\n",
        "\n",
        "        #creativity toggle here\n",
        "\n",
        "        y = self.mixer(Q, K, V, extra_score=bias, mask=mask)\n",
        "\n",
        "        y = y.transpose(1, 2).reshape(B, S, self.embed_dim)\n",
        "        return self.W_O(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "#   OmniHull Block\n",
        "# ----------------------------------------------------------------------\n",
        "class OmniHullBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, moe_petals, use=0):\n",
        "        super().__init__()\n",
        "        self.attn = PairwiseHullAttention(dim, heads, moe_petals, use=use)\n",
        "        self.hff  = VectorHull(dim, petals=moe_petals)\n",
        "        self.ln1, self.ln2 = nn.LayerNorm(dim), nn.LayerNorm(dim)\n",
        "        self.a1, self.a2   = nn.Parameter(torch.zeros(())), nn.Parameter(torch.zeros(()))\n",
        "\n",
        "    def _mix(self, x, y, a_raw):\n",
        "        alpha = F.softplus(a_raw) / (1 + F.softplus(a_raw))\n",
        "        return (1 - alpha) * x + alpha * y\n",
        "\n",
        "    def forward(self, x: torch.Tensor, mask = None):\n",
        "        x = self._mix(x, self.attn(self.ln1(x), mask), self.a1)\n",
        "        x = self._mix(x, self.hff(self.ln2(x)),         self.a2)\n",
        "        return x\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "#   GPT Wrapper with Causal Mask\n",
        "# ----------------------------------------------------------------------\n",
        "class ConvexGPT(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        embed_dim: int,\n",
        "        depth: int,\n",
        "        heads: int,\n",
        "        moe_petals: int,\n",
        "        creativity: bool = True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert embed_dim >= 1, \"embed_channels must be ≥1\"\n",
        "        self.embed_channels = embed_dim\n",
        "        self.embed_dim = 2 * embed_dim\n",
        "\n",
        "        # Embeddings only for even channels [0,2,4,...]\n",
        "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # Blocks operate on full embed_dim\n",
        "        self.blocks = nn.ModuleList([\n",
        "        OmniHullBlock(\n",
        "            self.embed_dim,\n",
        "            heads,\n",
        "            moe_petals,\n",
        "            use=1\n",
        "                  )\n",
        "            for i in range(depth)\n",
        "        ])\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(self.embed_dim)\n",
        "        self.head = nn.Linear(self.embed_dim, vocab_size, bias=False)\n",
        "        self.set_creativity(creativity)\n",
        "\n",
        "    @staticmethod\n",
        "    def _causal_mask(S: int, device: torch.device) -> torch.Tensor:\n",
        "        # shape (1, 1, S, S) where True = allowed\n",
        "        return torch.tril(torch.ones(S, S, dtype=torch.bool, device=device)) \\\n",
        "                   .unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "    def set_creativity(self, value: bool):\n",
        "        val = torch.tensor(value)\n",
        "        def recurse(m):\n",
        "            if hasattr(m, \"creative\"):\n",
        "                m.creative.copy_(val)\n",
        "            for child in m.children():\n",
        "                recurse(child)\n",
        "        recurse(self)\n",
        "\n",
        "    def forward(self, idx: torch.Tensor):\n",
        "        \"\"\"\n",
        "        idx: (B, S) token indices\n",
        "        returns logits: (B, S, vocab_size)\n",
        "        \"\"\"\n",
        "        B, S = idx.shape\n",
        "        device = idx.device\n",
        "        #stack 0::2 as embeddings, 1::2 as zeros for positional embeddings\n",
        "        x = torch.stack([self.token_emb(idx), torch.zeros_like(self.token_emb(idx))], dim=-1).reshape(idx.shape[0], idx.shape[1], 2 * self.token_emb.embedding_dim)\n",
        "        x = x.to(dtype=self.token_emb.weight.dtype)\n",
        "\n",
        "        # 3) build causal mask\n",
        "        mask = self._causal_mask(S, device)          # (1, 1, S, S)\n",
        "\n",
        "        # 4) apply each block (which will write φ into odd slots)\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x, mask)\n",
        "\n",
        "        # 5) final layernorm + head\n",
        "        x = self.ln_f(x)                             # (B, S, embed_dim)\n",
        "        logits = self.head(x)                        # (B, S, vocab_size)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "Fai0DHSh_lKM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "def wolf_update(p: torch.Tensor,\n",
        "                g: torch.Tensor,\n",
        "                state_p: torch.Tensor,\n",
        "                lr: float):\n",
        "    # define your constants here instead of capturing them\n",
        "    etcerta: float = 0.367879441\n",
        "    et:      float = 1.0 - etcerta\n",
        "\n",
        "    # same logic as before\n",
        "    update    = state_p * et + g * etcerta\n",
        "    new_state = state_p * et + update * etcerta\n",
        "    sign_agree = torch.sign(update) * torch.sign(g)\n",
        "    update    = update + (torch.rand_like(update)*2 - 1) * etcerta * update\n",
        "    p_new     = torch.where(sign_agree > 0, p - lr * update, p)\n",
        "    return p_new, new_state\n",
        "\n",
        "class Wolf(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3):\n",
        "        defaults = dict(lr=lr)\n",
        "        super().__init__(params, defaults)\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                self.state[p]['p'] = torch.zeros_like(p)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = closure() if closure is not None else None\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                state_p = self.state[p]['p']\n",
        "                p_new, new_state = wolf_update(p.data, p.grad, state_p, lr)\n",
        "                p.data.copy_(p_new)\n",
        "                state_p.copy_(new_state)\n",
        "        return loss\n",
        "\n",
        "# 1) Load data and meta as before\n",
        "data_dir  = os.path.dirname(base_dir)\n",
        "train_ids = np.fromfile(os.path.join(data_dir, 'train.bin'), dtype=np.uint16)\n",
        "val_ids   = np.fromfile(os.path.join(data_dir, 'val.bin'),   dtype=np.uint16)\n",
        "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
        "    meta = pickle.load(f)\n",
        "vocab_size = meta['vocab_size']\n",
        "\n",
        "# 2) Compute data‐marginal q[v]\n",
        "counts = np.bincount(train_ids, minlength=vocab_size).astype(float)\n",
        "q = torch.tensor(counts / counts.sum(), dtype=torch.float32, device=device)  # [V]\n",
        "\n",
        "# 3) Dataset + DataLoader\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, data, block_size):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        self.block_size = block_size\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx : idx + self.block_size]\n",
        "        y = self.data[idx + 1 : idx + self.block_size + 1]\n",
        "        return x, y\n",
        "\n",
        "block_size = 256\n",
        "train_loader = DataLoader(CharDataset(train_ids, block_size),\n",
        "                          batch_size=16, shuffle=True, drop_last=True)\n",
        "val_loader   = DataLoader(CharDataset(val_ids,   block_size),\n",
        "                          batch_size=16, shuffle=False, drop_last=True)\n",
        "virgin = ConvexGPT(vocab_size = vocab_size,embed_dim  = 128,depth  = 5,heads = 4,moe_petals = 4,creativity=True)\n",
        "\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in virgin.parameters()))\n",
        "model = torch.jit.script(virgin)\n",
        "model = model.to(device)\n",
        "optimizer = Wolf(model.parameters(), lr=1e-2)#or adam, but i prefer the WOLF.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "losses = []\n",
        "# 6) Train / eval functions\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        B, T, V = logits.shape\n",
        "        p = F.softmax(logits, dim=-1)      # (B, T, V)\n",
        "        # 1) Standard CE\n",
        "        loss = criterion(logits.view(B*T, V),\n",
        "                                yb.view(B*T))        # Forward\n",
        "        # Backprop\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        print(loss.item())\n",
        "        total_loss += loss.item()\n",
        "        losses.append(loss.item())\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for xb, yb in val_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        B, T, V = logits.shape\n",
        "        total_loss += criterion(logits.view(B*T,V),\n",
        "                                yb.view(B*T)).item()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "# 7) Run training\n",
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train_loss = train_epoch()\n",
        "    val_loss   = eval_epoch()\n",
        "    print(f\"Epoch {epoch:2d} | train: {train_loss:.4f} | val: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- helpers ---------------------------------------------------------\n",
        "def fenchel_decode(logits, tau=1.0, iters=3):\n",
        "    \"\"\"Fenchel‑dual KL‑regularised projection of -logits (energy).\"\"\"\n",
        "    energy = -logits                        # (B,V)\n",
        "    p = torch.full_like(energy, 1.0 / energy.size(-1))  # uniform start\n",
        "    for _ in range(iters):\n",
        "        p = torch.softmax((-energy / tau) + p.log(), dim=-1)\n",
        "    return p\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBNlDrh6DWqK",
        "outputId": "142b8d9a-30e9-4efe-e9d5-bc0e4151b4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters:  10304037\n",
            "4.3458685874938965\n",
            "4.335291385650635\n",
            "4.278759479522705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplt as plt\n",
        "plt.plot(losses)\n",
        "plt.show()\n",
        "# --- helpers ---------------------------------------------------------\n",
        "def fenchel_decode(logits, tau=1.0, iters=3):\n",
        "    \"\"\"Fenchel‑dual KL‑regularised projection of -logits (energy).\"\"\"\n",
        "    energy = -logits                        # (B,V)\n",
        "    p = torch.full_like(energy, 1.0 / energy.size(-1))  # uniform start\n",
        "    for _ in range(iters):\n",
        "        p = torch.softmax((-energy / tau) + p.log(), dim=-1)\n",
        "    return p\n",
        "\n",
        "# --- generation ------------------------------------------------------\n",
        "use_fenchel   = True          # flip to compare\n",
        "tau           = 1.0           # λ  (temperature analogue)\n",
        "max_new_tokens = 2000\n",
        "top_k          = 25\n",
        "block_size     = 256\n",
        "temperature    = 1.0\n",
        "\n",
        "bcontext_str = \"To be, or not to be,\"\n",
        "context_ids = torch.tensor([[ stoi[c] for c in bcontext_str ]],\n",
        "                           dtype=torch.long)\n",
        "context_ids = context_ids.to(device)\n",
        "\n",
        "\n",
        "generated = context_ids.clone()  # (1,T0)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for _ in range(max_new_tokens):\n",
        "    input_ids = generated[:, -block_size:]        # casual block\n",
        "    logits = model(input_ids)                     # (1,cur_T,V)\n",
        "    logits = logits[:, -1, :] / temperature       # (1,V)\n",
        "\n",
        "    # top‑k mask\n",
        "    if top_k is not None:\n",
        "        v, _ = torch.topk(logits, top_k)\n",
        "        logits[logits < v[:, [-1]]] = -1e10\n",
        "\n",
        "    if use_fenchel:\n",
        "        probs = fenchel_decode(logits, tau=tau, iters=3)\n",
        "    else:\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    next_id = torch.multinomial(probs, num_samples=1)   # (1,1)\n",
        "    generated = torch.cat([generated, next_id], dim=1)\n",
        "\n",
        "print('> ', ''.join(itos[i] for i in generated[0].tolist()))"
      ],
      "metadata": {
        "id": "_9GiSvYAnJnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "vec_hull = model.blocks[0].hff\n",
        "vec_hull.eval()\n",
        "\n",
        "# --- Step 1: Prepare padded token embeddings ---\n",
        "with torch.no_grad():\n",
        "    emb = model.token_emb.weight.detach().cpu()        # (V, D)\n",
        "    V, D = emb.shape\n",
        "    D_full = 2 * D\n",
        "    padded = torch.zeros((V, D_full), dtype=torch.float32)\n",
        "    padded[:, 0::2] = emb                              # interleave into even indices\n",
        "\n",
        "# --- Step 2: Forward pass through VectorHull ---\n",
        "with torch.no_grad():\n",
        "    out = vec_hull(padded).cpu().numpy()              # (V, D_full)\n",
        "\n",
        "# --- Step 3: Print basic stats ---\n",
        "print(\"\\n=== Output Stats ===\")\n",
        "print(f\"Shape: {out.shape}\")\n",
        "print(f\"Min:   {np.min(out)}\")\n",
        "print(f\"Max:   {np.max(out)}\")\n",
        "print(f\"Mean:  {np.mean(out)}\")\n",
        "print(f\"Std:   {np.std(out)}\")\n",
        "print(f\"NaNs:  {np.isnan(out).sum()}\")\n",
        "print(f\"Infs:  {np.isinf(out).sum()}\")\n",
        "\n",
        "# --- Step 4: Condition number (ill-conditioning) ---\n",
        "U, S, VT = np.linalg.svd(out - out.mean(axis=0), full_matrices=False)\n",
        "cond_number = S[0] / (S[-1] + 1e-12)\n",
        "print(f\"Condition number (PCA): {cond_number:.2e}\")\n",
        "print(f\"Singular values (first 10): {S[:10]}\")\n",
        "\n",
        "# --- Step 5: Histogram of outputs ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(out.flatten(), bins=100, color='blue', alpha=0.7)\n",
        "plt.title(\"Distribution of VectorHull Output Values\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Step 6: Gate saturation check ---\n",
        "gate_layer = vec_hull.gate\n",
        "with torch.no_grad():\n",
        "    gates = gate_layer(padded).squeeze().cpu().numpy()  # (V,)\n",
        "print(\"\\n=== Gate Stats ===\")\n",
        "print(f\"Min gate:   {gates.min():.4f}\")\n",
        "print(f\"Max gate:   {gates.max():.4f}\")\n",
        "print(f\"Mean gate:  {gates.mean():.4f}\")\n",
        "print(f\"Gates < 0.1: {(gates < 0.1).sum()}/{len(gates)}\")\n",
        "print(f\"Gates > 0.9: {(gates > 0.9).sum()}/{len(gates)}\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(gates, bins=50, color='green', alpha=0.7)\n",
        "plt.title(\"Distribution of ConvexGate Activations\")\n",
        "plt.xlabel(\"Gate value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WacaUrisctvH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}